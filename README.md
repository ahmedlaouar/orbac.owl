# ğŸ›¡ï¸ ORBAC-LLM: Conflict Resolution & Explanation with Ontologies and LLMs

This project addresses **access conflict resolution in ORBAC (Organization-Based Access Control)** policies using an **acceptance-based method**, and enhances it by generating **human-friendly natural language explanations** using **Large Language Models (LLMs)**.

It integrates **symbolic reasoning over OWL ontologies** with **neural explanation generation**, and supports **experiments, evaluation, and a web-based demo**.

---

## ğŸ¯ Project Aim

- Implement efficient **conflict resolution** in access control policies using the **acceptance method**.
- Leverage **LLMs** to produce **clear, natural language explanations** justifying granted or denied access.
- Provide tools for **experimentation, evaluation**, and **user-friendly demonstration**.

---

## ğŸ§± Project Structure

### `core/`
Houses all the core classes:
- `Policy`: Parses and loads ORBAC ontology and example graphs.
- `AccessRight`: Represents a specific access instance (Subject, Action, Object).
- `Explainer`: Interfaces with LLMs (HuggingFace API, Ollama, Transformers) to generate natural language explanations.
- `Evaluator`: Evaluates explanations based on **logical entailment, grammar, readability, and hallucination**.

### `dataset_generation/`
- Scripts to automatically generate synthetic **ORBAC policy instances and examples** in RDF format.
- Useful for scaling evaluations and testing generalization.

### `LLM_experiments/`
- Main engine to **run and evaluate experiments**.
- Supports:
  - `zero_shot`, `few_shot`, `interactive`, and `parameters_tuning` setups.
- Uses `optuna` for tuning, stores logs and results in:
  - `tmp/` (logs + best trial JSONs)
  - `results/` (CSV outputs, `figures/` for plots)
- Notebook: `OrBAC_LLMs_stats.ipynb` for full result analysis and visualization.

### `ontology/`
- The **core ORBAC ontology** (`.owl`) in OWL format.
- Example policies (`.owl`) demonstrating real and synthetic datasets for access rules and permissions.

### `queries.sparql/`
- Collection of **SPARQL queries** used throughout the codebase.
- Supports querying ontology data, resolving access rights, detecting conflicts, and collecting supports.

### `web-demo/`
- A **Streamlit web application** that:
  - Loads the ontology
  - Accepts input (subject, action, object)
  - Checks permissions
  - Displays **LLM-generated explanations** interactively.

---

## ğŸ” Setup & Hugging Face Token
To run the LLM experiments or the Streamlit web demo, you need a **Hugging Face access token** for loading transformer models.

1. **Get your token**
   
   Create an account at https://huggingface.co and generate a token at:
https://huggingface.co/settings/tokens

2. **Agree to model terms** (if required)

   Some models require you to manually accept their terms of use on their Hugging Face model card before access is granted.
   
   Make sure to visit the modelâ€™s page and click **â€œAgree and access modelâ€** if required. This applies in particular to:
    - `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`
    - `deepseek-ai/DeepSeek-R1-Distill-Qwen-7B`
    - `meta-llama/Llama-3.2-3B`
    - `meta-llama/Llama-3.2-3B-Instruct`
    - `google/gemma-2-9b`


3. **Save your token securely**

   Add your token in one of the following ways (depending on what part of the project you use):

    - **For LLM experiments** (`LLM_experiments/`): Create a `.env` file in the directory with:

      ```ini
      HF_TOKEN=your_token_here
      ```

    - **For the web demo** (`web-demo/`): Create a `.env` file in the directory:
      ```ini
      HF_TOKEN=your_token_here
      ```

    - **Alternatively**, for use with Streamlit: Create or edit the file `.streamlit/secrets.toml` with:
      ```toml
      HF_TOKEN = "your_token_here"
      ```

4. **Important**:
These token files (`.env`, `.streamlit/secrets.toml`) are listed in `.gitignore` to avoid exposing credentials. You must create them manually to run or reproduce the experiments or web app.

---

## ğŸ› ï¸ Technologies & Libraries

### ğŸ” Symbolic Reasoning
- `rdflib` â€“ RDF/OWL parsing and querying via SPARQL
- `owlready2` â€“ OWL ontologies manipulation (alternative or auxiliary)

### ğŸ“– LLM-based Explanations
- `transformers`, `torch`, `AutoModelForCausalLM`, `AutoTokenizer` â€“ LLMs for explanation generation
- `HuggingFace Inference API` â€“ Cloud-hosted LLMs
- `Ollama` â€“ Local LLM backend (optional)
- `optuna` â€“ Hyperparameter tuning for prompting strategies
- `python-dotenv` â€“ Secure environment variable management
- `nltk`, `simplenlg` â€“ Natural Language Generation utilities

### ğŸ§  Text Quality & Evaluation
- `language-tool-python` â€“ Grammar and style checking
- `textstat` â€“ Readability scoring
- `facebook/bart-large-mnli` â€“ NLI model for logical similarity scoring
- `language-tool-python` â€“ Grammar and style checking

### ğŸ“Š Experiment Management
- `pandas`, `numpy` â€“ Data processing and numerical computation
- `CSV`, `logging`, `logzero` â€“ Result tracking and experiment logging

### ğŸŒ Frontend
- `streamlit` â€“ Web interface for real-time demo and testing
- `streamlit_shadcn_ui` â€“ Enhanced UI components for Streamlit
- `htbuilder` â€“ HTML builder for custom component rendering

---

## ğŸš€ How to Use

1. **Prepare Dataset**: Use `dataset_generation/` or examples in `ontology/`.
2. **Run Experiments**:
    ```bash
    python LLM_experiments/experiments.py [zero_shot|few_shot|parameters_tuning|interactive] [model_name]
    ```
3. Analyze Results: Open the notebook in `LLM_experiments/OrBAC_LLMs_stats.ipynb`.
4. Try the Web Demo:
    ```bash
    streamlit run web-demo/app.py
    ```

## ğŸ“„ License

This project is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.  
To view a copy of this license, visit [https://creativecommons.org/licenses/by-nc-sa/4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).


## ğŸ‘©â€ğŸ”¬ Citation